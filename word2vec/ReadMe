1、语料词向量生成（针对搜狗语料库）
第一步：utils/splitFileUtils.java:切分大文件，并验证是否符合标准
第二步：utils/xmlFilesToTxt.java:将小文件逐一转化为xml文件，并从xml文件中逐一解析出需要的小文本集合
第三步：utils/mergeFileUtils.java:将小文件合并成大文件

第四步：utils/Normalize.java:顺对单个文档进行预处理 
第五步：nlpir/SegmentFile.java:使用NLPIR工具进行分词，直接对文件操作
第六步：utils/countFileWords.java:计算文档词数的功能

第七步：demo/FitDemo.java:生成词向量
第八步：nlpir/EntryOfTheCode.java:计算准确率

2、实验数据整理
第一步：data/FileToLine.java:生成每个类别文件的txt，使其每一行对应一个文件
第二步：data/FormatFile.java:预处理
第三部：data/SegmentDoc.java:分词
第四步：data/keyWords.java:获取每个文档的idf值
第五步：data/documentTF.java:获取每个文件词的tf值
3、我的计划
	2017/02/25写，未来三天
		2.25：完成关键词提取，跑通文档分类算法，准确率不能低于60%
		2.26：调整参数提高准确率
		2.27：开始写大小论文
		
4、我的进度（持续更新）：
2017/02/25
	今天上午完成关键词提取的功能
	
	
	
	