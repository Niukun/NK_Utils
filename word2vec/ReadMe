1、语料词向量生成（针对搜狗语料库）
第一步：utils/splitFileUtils.java:切分大文件，并验证是否符合标准
第二步：utils/xmlFilesToTxt.java:将小文件逐一转化为xml文件，并从xml文件中逐一解析出需要的小文本集合
第三步：utils/mergeFileUtils.java:将小文件合并成大文件

第四步：utils/Normalize.java:顺对单个文档进行预处理 
第五步：nlpir/SegmentFile.java:使用NLPIR工具进行分词，直接对文件操作
第六步：utils/countFileWords.java:计算文档词数的功能

第七步：demo/FitDemo.java:生成词向量
第八步：nlpir/EntryOfTheCode.java:计算准确率

2、实验数据整理
第一步：data/FileToLine.java:生成每个类别文件的txt，使其每一行对应一个文件
第二步：data/FormatFile.java:预处理
第三部：data/SegmentDoc.java:分词
第四步：demo/FitDemo.java:生成词向量
第五步：nlpir/EntryOfTheCode2017.java:进行实验，得到准确率

其中：data/keyWords.java:获取每个文档的tf、tfidf值（工具类）

3、我的计划
	2017/02/25写，未来三天
		2.25：完成关键词提取，跑通文档分类算法，准确率不能低于60%
		2.26：调整参数提高准确率
		2.27：开始写大小论文
		
4、我的进度（持续更新）：
2017/02/25
	今天上午完成关键词提取的功能
	
2017/02/26
	今天上午完成准确率计算，昨天没有得到准确率，今天压力大了，还有参数调整和优化。
	


参考：
NLPIR官网：http://ictclas.nlpir.org/
NLPIR github:https://github.com/NLPIR-team/NLPIR
NLPIR使用教程：http://www.cnblogs.com/wukongjiuwo/p/4092480.html
	